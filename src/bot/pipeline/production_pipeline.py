"""
Pipeline de production complet pour Revolver.bot
Orchestration : Veille â†’ Analyse â†’ Livrables â†’ Distribution
"""

# Standard library imports
import asyncio
import json
import logging
import os
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

from .data_collectors import DataCollectors
from .data_analyzer import DataAnalyzer
from .deliverable_generator import DeliverableGenerator

logger = logging.getLogger(__name__)

@dataclass
class PipelineConfig:
    """Configuration du pipeline de production"""
    # Sources
    instagram_competitors: List[str]
    linkedin_competitors: List[str]
    tiktok_hashtags: List[str]
    
    # Livrables
    generate_weekly: bool = True
    generate_monthly: bool = False
    generate_recommendation: bool = False
    generate_newsletter: bool = False
    
    # Limites
    posts_per_competitor: int = 10
    max_hashtag_posts: int = 25
    analysis_depth: str = "standard"  # basic, standard, deep
    
    # Output
    output_dir: str = "output"
    save_raw_data: bool = True
    save_analysis: bool = True

@dataclass
class PipelineResult:
    """RÃ©sultat du pipeline de production"""
    pipeline_id: str
    timestamp: datetime
    config: PipelineConfig
    
    # Data collectÃ©e
    instagram_data: Dict[str, Any]
    linkedin_data: Dict[str, Any]
    tiktok_data: Dict[str, Any]
    
    # Analysis
    insights: Dict[str, Any]
    trends: Dict[str, Any]
    competitive_analysis: Dict[str, Any]
    
    # Livrables gÃ©nÃ©rÃ©s
    weekly_report: Optional[str] = None
    monthly_report: Optional[str] = None
    recommendation_slides: Optional[str] = None
    newsletter: Optional[str] = None
    
    # MÃ©triques
    execution_time: float = 0.0
    data_points_collected: int = 0
    success_rate: float = 0.0
    errors: List[str] = None
    
    def to_dict(self) -> Dict:
        result = asdict(self)
        # Fix datetime serialization
        if hasattr(self, 'timestamp') and self.timestamp:
            result['timestamp'] = self.timestamp.isoformat()
        return result

class ProductionPipeline:
    """
    Pipeline de production complet pour Revolver.bot
    """
    
    def __init__(self, config: PipelineConfig):
        self.config = config

        # Initialiser les modules spÃ©cialisÃ©s
        self.data_collectors = DataCollectors(config)
        self.data_analyzer = DataAnalyzer(None, None)  # TODO: injecter les dÃ©pendances
        self.deliverable_generator = DeliverableGenerator(None, Path(config.output_dir))

        # CrÃ©er rÃ©pertoire de sortie
        self.output_path = Path(config.output_dir)
        self.output_path.mkdir(exist_ok=True)
    
    async def run_full_pipeline(self, brief_path: Optional[str] = None) -> PipelineResult:
        """
        ExÃ©cute le pipeline complet de production
        
        Args:
            brief_path: Chemin vers brief PDF (optionnel)
        
        Returns:
            RÃ©sultat complet du pipeline
        """
        start_time = datetime.now()
        pipeline_id = f"pipeline_{start_time.strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"ğŸš€ DÃ©marrage pipeline {pipeline_id}")
        
        result = PipelineResult(
            pipeline_id=pipeline_id,
            timestamp=start_time,
            config=self.config,
            instagram_data={},
            linkedin_data={},
            tiktok_data={},
            insights={},
            trends={},
            competitive_analysis={},
            errors=[]
        )
        
        try:
            # 1. COLLECTE DE DONNÃ‰ES
            logger.info("ğŸ“¡ Phase 1: Collecte de donnÃ©es")
            await self._collect_data(result)
            
            # 2. ANALYSE IA
            logger.info("ğŸ§  Phase 2: Analyse IA")
            await self._analyze_data(result, brief_path)
            
            # 3. GÃ‰NÃ‰RATION LIVRABLES
            logger.info("ğŸ“Š Phase 3: GÃ©nÃ©ration livrables")
            await self._generate_deliverables(result, brief_path)
            
            # 4. SAUVEGARDE
            logger.info("ğŸ’¾ Phase 4: Sauvegarde")
            await self._save_results(result)
            
            # Calcul mÃ©triques finales
            end_time = datetime.now()
            result.execution_time = (end_time - start_time).total_seconds()
            result.success_rate = self._calculate_success_rate(result)
            
            logger.info(f"âœ… Pipeline {pipeline_id} terminÃ© en {result.execution_time:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ Erreur pipeline {pipeline_id}: {e}")
            result.errors.append(str(e))
            result.success_rate = 0.0
        
        return result
    
    async def _collect_data(self, result: PipelineResult):
        """Collecte les donnÃ©es depuis toutes les sources"""

        # Utiliser le module de collecte spÃ©cialisÃ©
        try:
            result.instagram_data = await self.data_collectors.collect_instagram_data()
            result.linkedin_data = await self.data_collectors.collect_linkedin_data()
            result.tiktok_data = await self.data_collectors.collect_tiktok_data()

            # Compter les points de donnÃ©es
            total_instagram = sum(len(posts) for posts in result.instagram_data.values())
            total_linkedin = sum(len(posts) for posts in result.linkedin_data.values())
            total_tiktok = sum(len(posts) for posts in result.tiktok_data.values())

            result.data_points_collected = total_instagram + total_linkedin + total_tiktok
            logger.info(f"âœ… Collecte terminÃ©e: {result.data_points_collected} points de donnÃ©es")

        except Exception as e:
            logger.error(f"âŒ Erreur collecte: {e}")
            result.errors.append(f"Collecte: {e}")
    
    async def _analyze_data(self, result: PipelineResult, brief_path: Optional[str]):
        """Analyse les donnÃ©es collectÃ©es avec IA"""

        try:
            # Analyser le brief si fourni
            brief_analysis = {}
            if brief_path:
                logger.info(f"ğŸ“„ Analyse brief: {brief_path}")
                brief_analysis = await self.data_analyzer.analyze_brief(brief_path)

            # Utiliser le module d'analyse pour tout le reste
            logger.info("ğŸ¯ Analyse complÃ¨te des donnÃ©es")
            result.competitive_analysis = await self.data_analyzer.analyze_competitive_data(result)
            result.trends = self.data_analyzer.detect_trends(result)
            result.insights = await self.data_analyzer.generate_insights(result, brief_analysis)

        except Exception as e:
            logger.error(f"âŒ Erreur analyse: {e}")
            result.errors.append(f"Analyse: {e}")
    
    async def _generate_deliverables(self, result: PipelineResult, brief_path: Optional[str]):
        """GÃ©nÃ¨re tous les livrables demandÃ©s"""

        try:
            # Utiliser le module de gÃ©nÃ©ration spÃ©cialisÃ©
            if self.config.generate_weekly:
                logger.info("ğŸ“Š GÃ©nÃ©ration Weekly Report")
                result.weekly_report = str(await self.deliverable_generator.generate_weekly_report(result))

            if self.config.generate_monthly:
                logger.info("ğŸ“ˆ GÃ©nÃ©ration Monthly Report")
                result.monthly_report = str(await self.deliverable_generator.generate_monthly_report(result))

            if self.config.generate_recommendation and brief_path:
                logger.info("ğŸ¨ GÃ©nÃ©ration Recommendation Slides")
                result.recommendation_slides = str(await self.deliverable_generator.generate_recommendation_slides(result, brief_path))

            if self.config.generate_newsletter:
                logger.info("ğŸ“§ GÃ©nÃ©ration Newsletter")
                result.newsletter = str(await self.deliverable_generator.generate_newsletter(result))

        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration livrables: {e}")
            result.errors.append(f"Livrables: {e}")
    
